Let $\Omega$ be a domain with boundary $\partial\Omega$ and let $\mathcal{L}$ be a suitable linear differential operator. We consider the following Dirichlet problem:
\begin{equation}
\label{DirichletProb}
    \left\{
    \begin{array}{cc}
        \mathcal{L}u=f & \text{on } \Omega  \\
         u = g  & \text{ on } \partial\Omega
    \end{array}
    \right.
\end{equation}
where the functions $f,g$ may be noisy, typically Gaussian. The operator $\mathcal{L}$ may also be random. For simplicity we will take $g=0$ and will assume that $\mathcal{L}$ is deterministic. We seek the solution in some appropriate Hilbert space of functions $\mathcal{H}$. Formally we have $u=\mathcal{L}^{-1}f$.

\begin{remark}
If $f$ is Gaussian, i.e. $f\sim\mathcal{N}(\bar{f},K)$, then $(u,f)$ is joint Gaussian:
\begin{equation}
\label{trueJoint}
    \begin{pmatrix}
        f \\
        u
    \end{pmatrix} \sim \mathcal{N}\left(
    \begin{pmatrix}
    \bar{f} \\
    \mathcal{L}^{-1}\bar{f}
    \end{pmatrix},
    \begin{pmatrix}
    K & K(\mathcal{L}^{-1})^{*} \\
    \mathcal{L}^{-1}K & \mathcal{L}^{-1}K(\mathcal{L}^{-1})^{*}
    \end{pmatrix}
    \right)
\end{equation}
provided that $\mathcal{L}^{-1}$ is bounded.
\end{remark}

Let us consider placing a Gaussian prior on $u$, $u\sim\mathcal{N}(0,V)$, where we control $V$ so that $u$ is almost surely in some appropriate subspace $\mathcal{U}\subset\mathcal{H}$ where the linear operator $\mathcal{L}$ restricted to this subspace is bounded. I.e. $\mathcal{L}:\mathcal{U}\rightarrow \mathcal{U}^{\prime}$ is bounded where $\mathcal{U}\subset\mathcal{H}\subset\mathcal{U}^{\prime}$.
\begin{remark}
    We shall assume here that the subspace $\mathcal{U}$ is reflexive so that $\mathcal{U}^{\prime\prime}$ can be identified with $\mathcal{U}$.
\end{remark}

Now consider the following information operators:
\begin{equation*}
    I_{j}\cdot=\int_{\Omega}\psi_{j}\cdot\mathrm{d}x, \hspace{0.5cm} j=1,\dots,J
\end{equation*}
where $\psi_{j}\in\mathcal{F}_{h}$ for $j=1,\dots,J$ where $\mathcal{F}_{h}$ is some discretisation of the function space $\mathcal{H}$ (and $h$ is the mesh size).
\begin{remark}
Think of the $\{\psi_{j}\}$ as a basis for the finite element spaces.
\end{remark}

Let $\mathcal{I}=(I_1,\dots,I_J)^T$. We have,
\begin{equation*}
    \mathcal{I}\mathcal{L}u=(I_{1}\mathcal{L}u,\dots,I_{J}\mathcal{L}u)\in\mathbb{R}^{J}
\end{equation*}
and under our assumptions on $V$ we have that,
\begin{equation}
    \label{jointInfoDist}
    \begin{pmatrix}
    u \\
    \mathcal{I}\mathcal{L}u
    \end{pmatrix} =
    \begin{pmatrix}
    I \\ \mathcal{I}\mathcal{L}
    \end{pmatrix} u \sim \mathcal{N}\left(
    \begin{pmatrix}
    0 \\
    \mathbf{0}_J
    \end{pmatrix},
    \begin{pmatrix}
    V & V\mathcal{L}^{*}\mathcal{I}^{*} \\
    \mathcal{I}\mathcal{L}V & \mathcal{I}\mathcal{L}V\mathcal{L}^{*}\mathcal{I}^{*}
    \end{pmatrix}
    \right)
\end{equation}

Under the assumption that (\ref{DirichletProb}) holds we have $\mathcal{I}\mathcal{L}u=\mathcal{I}f=:F$. Assuming now that we fix a realisation of $f$ (and so $F$ is fixed) we have by conditioning (see Notes 3 for a justification of why this is valid) that:
\begin{equation}
    \label{conditionalDistnFixed_f}
    u|\{\mathcal{I}\mathcal{L}u=F,f\}\sim\mathcal{N}(a,\Sigma)=:\mu_{a,\Sigma}
\end{equation}
where,
\begin{equation}
    \label{post_mean_before_averaging}
    a = V\mathcal{L}^{*}\mathcal{I}^{*}(\mathcal{I}\mathcal{L}V\mathcal{L}^{*}\mathcal{I}^{*})^{-1}F
\end{equation}
\begin{equation}
    \label{post_var_before_averaging}
    \Sigma = V - V\mathcal{L}^{*}\mathcal{I}^{*}(\mathcal{I}\mathcal{L}V\mathcal{L}^{*}\mathcal{I}^{*})^{-1}\mathcal{I}\mathcal{L}V
\end{equation}

\begin{remark}
We use the notation $\mu_{m,A}$ to denote a Gaussian measure (in arbitrary dimensions) with mean $m$ and covariance $A$. The space (and hence the dimension) should be clear from the domain of the covariance operator.
\end{remark}

We will now assume that $f$ is distributed as $f\sim\mathcal{N}(\bar{f},K)$ and we will seek to marginalize over $f$ in (\ref{conditionalDistnFixed_f}) so as to obtain the ``average" conditional distribution over all possible values of $f$. To do so we first note:
\begin{equation}
    f\sim\mathcal{N}(\bar{f},K)=:\mu_{\bar{f},K} \implies \mathcal{I}f=F\sim\mathcal{N}(\mathcal{I}\bar{f},\mathcal{I}K\mathcal{I}^{*})=:\mu_{\bar{F},K_{\mathcal{I}}}
\end{equation}
where $\bar{F}:=\mathcal{I}\bar{f}$ and $K_{\mathcal{I}}:=\mathcal{I}K\mathcal{I}^{*}$. In order to specify the ``average" conditional distribution it suffices to compute the expectation of arbitrary bounded cylindrical test functions $\phi(u^{N}):=\phi(u(x_1),\dots,u(x_{N}))$ since the $\sigma-$algebra generated by cylinder sets coincides with the Borel $\sigma-$algebra (see for instance Theorem 2.1.1 in \cite{lunardi2015infinite}). We must thus compute:
\begin{equation}
    \int\int\phi(u^{N})\mu_{a,\Sigma}(\mathrm{d}u)\mu_{\bar{f},K}(\mathrm{d}f)
\end{equation}
Note that $u^{N}=Pu$ where the bounded linear operator $P:\mathcal{H}\rightarrow\mathbb{R}^{N}$ is defined by $Ph:=(h(x_1),\dots,h(x_N))^T$ for any function $h$. Thus, $u^{N}$ is multivariate normal, i.e., $u^{N}\sim\mathcal{N}(Pa,P\Sigma P^{*})=:\mu_{Pa,\Sigma_{N}}$ where $\Sigma_{N}:=P\Sigma P^{*}$ is the $N\times N$ covariance matrix of $u^{N}$. We thus have:
\begin{equation}
    \int\int\phi(u^{N})\mu_{a,\Sigma}(\mathrm{d}u)\mu_{\bar{f},K}(\mathrm{d}f) = \int\int\phi(u^{N})\mu_{Pa,\Sigma_N}(\mathrm{d}u^{N})\mu_{\bar{f},K}(\mathrm{d}f)
\end{equation}
We note that $Pa=PAF$ where $A:= V\mathcal{L}^{*}\mathcal{I}^{*}(\mathcal{I}\mathcal{L}V\mathcal{L}^{*}\mathcal{I}^{*})^{-1}$. Since the conditional distribution of $u$ (\ref{conditionalDistnFixed_f}) and hence of $u^{N}$ only depends on $f$ through $F\in\mathbb{R}^{J}$ we can thus write:
\begin{equation}
    \int\int\phi(u^{N})\mu_{Pa,\Sigma_N}(\mathrm{d}u^{N})\mu_{\bar{f},K}(\mathrm{d}f)=\int\int\phi(u^{N})\mu_{Pa,\Sigma_N}(\mathrm{d}u^{N})\mu_{\bar{F},K_{\mathcal{I}}}(\mathrm{d}F)
\end{equation}
Both measures in the above integral are now multivariate normal and so we have:
\begin{align}
    \int\int&\phi(u^{N})\mu_{Pa,\Sigma_N}(\mathrm{d}u^{N})\mu_{\bar{F},K_{\mathcal{I}}}(\mathrm{d}F)= \nonumber \\ &=\frac{1}{Z_u}\int\int\phi(u^{N})\exp\left(-\frac{1}{2}\left\langle u^{N}-PAF,\Sigma_{N}^{-1}(u^{N}-PAF) \right\rangle\right)\mu_{\bar{F},K_{\mathcal{I}}}(\mathrm{d}F)\mathrm{d}u^{N} \nonumber \\
    &=\frac{1}{Z_{u}Z_{f}}\int\int\phi(u^{N})\exp\left(-\frac{1}{2}\left\langle u^{N}-PAF,\Sigma_{N}^{-1}(u^{N}-PAF)\right\rangle\right)\exp\left(-\frac{1}{2}\left\langle F-\bar{F},K_{\mathcal{I}}^{-1}(F-\bar{F}) \right\rangle\right)\mathrm{d}F\mathrm{d}u^{N}
\end{align}
where the normalization constants are $Z_u:=(2\pi)^{N/2}\det(\Sigma_N)^{1/2}$ and $Z_f:=(2\pi)^{J/2}\det(K_\mathcal{I})^{1/2}$. We now need to compute the integral over $F$. In order to do so we combine the exponents in (11) into a quadratic in $F$ in order to be able to use the well-known formula of a multidimensional Gaussian integral. Going through the algebra we obtain:
\begin{align}
    \frac{1}{Z_{u}Z_{f}}&\int\int\phi(u^{N})\exp\Bigg(-\frac{1}{2}\Big(\left\langle u^{N},\Sigma_{N}^{-1}u^{N} \right\rangle - 2\left\langle \Sigma_{N}^{-1}PAF,u^{N}\right\rangle + \left\langle F,A^{*}P^{*}\Sigma_{N}^{-1}PAF\right\rangle \nonumber \\
    &+ \left\langle F,K_{\mathcal{I}}^{-1}F\right\rangle - 2 \left\langle K_{\mathcal{I}}^{-1}\bar{F},F \right\rangle + \left\langle \bar{F},K_{\mathcal{I}}^{-1}\bar{F}\right\rangle \Big)\Bigg)\mathrm{d}F\mathrm{d}u^{N} = \nonumber \\
    &=\frac{1}{Z_{u}Z_{f}}\int\phi(u^{N})\exp\left(-\frac{1}{2}\left(\left\langle u^{N},\Sigma_{N}^{-1} u^{N} \right\rangle + \left\langle \bar{F},K_{\mathcal{I}}^{-1}\bar{F} \right\rangle\right)\right) \cdot \nonumber \\
    &\left(\int\exp\left(-\frac{1}{2}\left\langle F,BF \right\rangle + \left\langle A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F},F \right\rangle\right)\mathrm{d}F\right)\mathrm{d}u^{N}
\end{align}
where $B:=\left(A^{*}P^{*}\Sigma_{N}^{-1}PA+K_{\mathcal{I}}^{-1}\right)$. Computing the inner integral over $F$ we thus obtain:
\begin{align}
    \frac{(2\pi)^{J/2}}{Z_{u}Z_{f}\det(B)^{1/2}}\int\phi(u^{N})\exp&\left(\frac{1}{2}\left\langle A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F}, B^{-1}\left(A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F}\right) \right\rangle\right. \nonumber \\
    &\left.-\frac{1}{2}\left(\left\langle u^{N}, \Sigma_{N}^{-1}u^{N}\right\rangle + \left\langle \bar{F},K_{\mathcal{I}}^{-1}\bar{F} \right\rangle \right)\right)\mathrm{d}u^{N}
\end{align}
We now focus on the terms in the exponent and simplify these as follows:
\begin{align}
    &\frac{1}{2}\left\langle A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F}, B^{-1}\left(A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F}\right) \right\rangle -\frac{1}{2}\left(\left\langle u^{N}, \Sigma_{N}^{-1}u^{N}\right\rangle + \left\langle \bar{F},K_{\mathcal{I}}^{-1}\bar{F} \right\rangle \right) =  \nonumber \\
    &=-\frac{1}{2}\Big( \left\langle u^{N}, \Sigma_{N}^{-1}u^{N}\right\rangle + \left\langle \bar{F}, K_{\mathcal{I}}^{-1}\bar{F} \right\rangle - \left\langle A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F}, B^{-1}\left(A^{*}P^{*}\Sigma_{N}^{-1}u^{N} + K_{\mathcal{I}}^{-1}\bar{F}\right) \right\rangle \Big) \nonumber \\
    &=-\frac{1}{2}\Big(\left\langle u^{N}, \Sigma_{N}^{-1}u^{N}\right\rangle + \left\langle \bar{F}, K_{\mathcal{I}}^{-1}\bar{F} \right\rangle - \left\langle u^{N},\Sigma_{N}^{-1}PAB^{-1}A^{*}P^{*}\Sigma_{N}^{-1}u^{N} \right\rangle \nonumber \\
    &- 2\left\langle u^{N},\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F} \right\rangle - \left\langle \bar{F}, K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1}\bar{F} \right\rangle \Big) \nonumber \\
    &= -\frac{1}{2}\Big( \left\langle u^{N}, (\Sigma_{N}^{-1} - \Sigma_{N}^{-1}PAB^{-1}A^{*}P^{*}\Sigma_{N}^{-1})u^{N} \right\rangle - 2 \left\langle u^{N},\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F} \right\rangle + \left\langle \bar{F}, (K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1})\bar{F} \right\rangle \Big) \nonumber \\
    &=-\frac{1}{2}\Big( \left\langle u^{N}, \Sigma_{\mathcal{I}}^{-1}u^{N} \right\rangle - 2 \left\langle u^{N},\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F} \right\rangle + \left\langle \bar{F}, (K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1})\bar{F} \right\rangle \Big) \label{exponent}
\end{align}
where $\Sigma_{\mathcal{I}}:=\Sigma_{N} + PAK_{\mathcal{I}}A^{*}P^{*}$. The inverse of $\Sigma_{\mathcal{I}}$ is indeed the coefficient matrix for the quadratic term in $u^{N}$ in (\ref{exponent}). This can be seen by utilizing the Woodbury matrix identity as follows:
\begin{align*}
    \Sigma_{\mathcal{I}}^{-1}&=(\Sigma_{N} + PAK_{\mathcal{I}}A^{*}P^{*})^{-1} \\
    &=\Sigma_{N}^{-1}-\Sigma_{N}^{-1}PA(K_{\mathcal{I}}^{-1}+A^{*}P^{*}\Sigma_{N}^{-1}PA)^{-1}A^{*}P^{*}\Sigma_{N}^{-1} \\
    &=\Sigma_{N}^{-1}-\Sigma_{N}^{-1}PAB^{-1}A^{*}P^{*}\Sigma_{N}^{-1}
\end{align*}
We now complete the square (in terms of $u^{N}$) to obtain:
\begin{align}
    -&\frac{1}{2}\Big(\left\langle u^{N}-h^{N},\Sigma_{\mathcal{I}}^{-1}(u^{N}-h^{N}) \right\rangle + \left\langle \bar{F}, (K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1})\bar{F} \right\rangle - \left\langle \Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F},\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F} \right\rangle \Big) = \nonumber \\
    &=-\frac{1}{2}\Big(\left\langle u^{N}-h^{N},\Sigma_{\mathcal{I}}^{-1}(u^{N}-h^{N}) \right\rangle + \left\langle \bar{F}, (K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1})\bar{F} \right\rangle\Big)
\end{align}
where $h^{N}:=\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F}$. We now show that the term quadratic in $\bar{F}$ vanishes by showing that the coefficient matrix of $\bar{F}$ is equal to the zero matrix. Note that this coefficent matrix can be rewritten as:
\begin{align*}
    &K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1} = \\
    &=K_{\mathcal{I}}^{-1}K_{\mathcal{I}}K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}K_{\mathcal{I}}^{-1}-K_{\mathcal{I}}^{-1}B^{-1}A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1} \\
    &= K_{\mathcal{I}}^{-1}(K_{\mathcal{I}}-B^{-1}-B^{-1}A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1})K_{\mathcal{I}}^{-1} \\
    &=K_{\mathcal{I}}^{-1}B^{-1}(BK_{\mathcal{I}}B-B-A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA)B^{-1}K_{\mathcal{I}}^{-1}
\end{align*}
and so showing that it is the zero matrix is equivalent to showing that $(BK_{\mathcal{I}}B-B-A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA)$ is the zero matrix. This can be shown as follows:
\begin{align*}
    &BK_{\mathcal{I}}B-B-A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA = \\
    &=(A^{*}P^{*}\Sigma_{N}^{-1}PA+K_{\mathcal{I}}^{-1})K_{\mathcal{I}}B-B-A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA \\
    &=A^{*}P^{*}\Sigma_{N}^{-1}PAK_{\mathcal{I}}B+B-B-A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA \\
    &=A^{*}P^{*}\Sigma_{N}^{-1}PAK_{\mathcal{I}}(A^{*}P^{*}\Sigma_{N}^{-1}PA+K_{\mathcal{I}}^{-1})-A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA \\
    &=A^{*}P^{*}\Sigma_{N}^{-1}PAK_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA + A^{*}P^{*}\Sigma_{N}^{-1}PA - A^{*}P^{*}\Sigma_{N}^{-1}\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PA \\
    &= A^{*}P^{*}\Sigma_{N}^{-1}(PAK_{\mathcal{I}}A^{*}P^{*}+\Sigma_{N}-\Sigma_{\mathcal{I}})\Sigma_{N}^{-1}PA = 0
\end{align*}
where the last equality follows by the definition of $\Sigma_{\mathcal{I}}$. Thus, our integral simplifies to:
\begin{equation}
    \frac{(2\pi)^{J/2}}{Z_{u}Z_{f}\det(B)^{1/2}}\int\phi(u^{N})\exp\Big(-\frac{1}{2}\left\langle u^{N}-h^{N},\Sigma_{\mathcal{I}}^{-1}(u^{N}-h^{N}) \right\rangle\Big)\mathrm{d}u^{N}
\end{equation}
We now focus on simplifying the normalizing constants in front of the integral:
\begin{align*}
    \frac{(2\pi)^{J/2}}{Z_{u}Z_{f}\det(B)^{1/2}}&=\frac{(2\pi)^{J/2}}{(2\pi)^{N/2}\det(\Sigma_N)^{1/2}(2\pi)^{J/2}\det(K_\mathcal{I})^{1/2}\det(B)^{1/2}}= \\
    &=\frac{1}{(2\pi)^{N/2}\det(\Sigma_N)^{1/2}\det(K_\mathcal{I})^{1/2}\det(B)^{1/2}}
\end{align*}
To proceed we note that $\det{B}$ can be rewritten as follows:
\begin{align*}
    \det(B)&=\det(A^{*}P^{*}\Sigma_{N}^{-1}PA + K_{\mathcal{I}}^{-1}) \\
    &=\det(K_{\mathcal{I}}^{-1}(I+K_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA)) \\
    &=\det(K_{\mathcal{I}}^{-1})\det(I+(K_{\mathcal{I}}A^{*}P^{*})(\Sigma_{N}^{-1}PA))) \\
    &=\det(K_{\mathcal{I}})^{-1}\det(I+\Sigma_{N}^{-1}PAK_{\mathcal{I}}A^{*}P^{*})
\end{align*}
where we have utilized Sylvester's determinant theorem (\textit{note: the identity matrices in the last two lines are of different sizes}). We can now finish up the simplification of the constants outside the integral:
\begin{align*}
    &\frac{1}{(2\pi)^{N/2}\det(\Sigma_N)^{1/2}\det(K_\mathcal{I})^{1/2}\det(B)^{1/2}} \\
    &=\frac{1}{(2\pi)^{N/2}\det(\Sigma_N)^{1/2}\det(K_\mathcal{I})^{1/2}\det(K_{\mathcal{I}})^{-1/2}\det(I_{N}+\Sigma_{N}^{-1}PAK_{\mathcal{I}}A^{*}P^{*})^{1/2}} \\
    &= \frac{1}{(2\pi)^{N/2}\det(\Sigma_{N} + PAK_{\mathcal{I}}A^{*}P^{*})^{1/2}} \\
    &=\frac{1}{(2\pi)^{N/2}\det(\Sigma_{\mathcal{I}})^{1/2}}
\end{align*}
Thus, our integral becomes:
\begin{align}
    \int&\phi(u^{N})\frac{1}{(2\pi)^{N/2}\det(\Sigma_{\mathcal{I}})^{1/2}}\exp\left(-\frac{1}{2}\left\langle u^{N}-h^{N}, \Sigma_{\mathcal{I}}^{-1}(u^{N}-h^{N}) \right\rangle\right)\mathrm{d}u^N = \nonumber \\
    =&\int\phi(u^{N})\mu_{h^{N},\Sigma_{\mathcal{I}}}(\mathrm{d}u^N)
\end{align}
from which we see that we have obtained the expectation of $\phi$ w.r.t. a multivariate Gaussian with mean and covariance given by:
\begin{equation}
    h^{N}:=\Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F}=PA\bar{F}
\end{equation}
\begin{equation}
    \Sigma_{\mathcal{I}}=P(\Sigma+AK_{\mathcal{I}}A^{*})P^{*}
\end{equation}

Note that we have simplified the mean $h^N$ of this multivariate Gaussian as follows:
\begin{align*}
    h^N &= \Sigma_{\mathcal{I}}\Sigma_{N}^{-1}PAB^{-1}K_{\mathcal{I}}^{-1}\bar{F} \\
    &=(\Sigma_N+PAK_{\mathcal{I}}A^{*}P^{*})\Sigma_{N}^{-1}PA(K_{\mathcal{I}}B)^{-1}\bar{F} \\
    &=PA(K_{\mathcal{I}}B)^{-1}\bar{F}+PAK_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA(K_{\mathcal{I}}B)^{-1}\bar{F} \\
    &=PA(I+K_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA)(K_{\mathcal{I}}B)^{-1}\bar{F} \\
    &=PA(I+K_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA)(K_{\mathcal{I}}(K_{\mathcal{I}}^{-1}+A^{*}P^{*}\Sigma_{N}^{-1}PA))^{-1}\bar{F}\\
    &=PA(I+K_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA)(I+K_{\mathcal{I}}A^{*}P^{*}\Sigma_{N}^{-1}PA)^{-1}\bar{F}\\
    &=PA\bar{F}
\end{align*}

Thus, we conclude that ``averaging" over $f$ gives the following Gaussian posterior:
\begin{equation}
    \label{posteriorDist}
    \mathcal{N}\left(A\bar{F},\Sigma+AK_{\mathcal{I}}A^{*}\right)
\end{equation}
where we recall that the operator $A$ is $A= V\mathcal{L}^{*}\mathcal{I}^{*}(\mathcal{I}\mathcal{L}V\mathcal{L}^{*}\mathcal{I}^{*})^{-1}$.
