We now introduce the general framework we will be considering. This will be split into two parts. In the first we shall be considering spatial problems without any time dependence, while in the second part we will consider problems with time dependence. We aim to describe how the two priors will be formed and then discuss how further inference will be carried out when observational data from the physical system is available.


\subsection{Spatial Boundary Value Problems}

We first consider PDEs which do not have any time dependence. Let $\Omega$ be a domain with boundary $\partial\Omega$ and let $\mathcal{L}$ be a suitable linear differential operator. We will focus on the following Dirichlet problem:
\begin{equation}
\label{DirichletProb}
    \left\{
    \begin{array}{cc}
        \mathcal{L}u=f & \text{on } \Omega  \\
         u = g  & \text{ on } \partial\Omega
    \end{array}
    \right.
\end{equation}
where the functions $f,g$ may be noisy, typically Gaussian. The operator $\mathcal{L}$ may also be random. For simplicity we will take $g=0$ and will assume that $\mathcal{L}$ is deterministic. We will also now assume that $f$ is Gaussian, i.e. $f\sim\mathcal{N}(\bar{f},K)$. We seek the solution in some appropriate Hilbert space of functions $\mathcal{H}$. We now discuss how the two priors over the solution space are formed. The first prior will essentially come from the true solution of the PDE while the second will be the ``output" of a probabilistic numerical method\footnote{Note that in our discussion of probabilistic numerical methods we referred to the output as being a posterior distribution over the solution of the problem; here we are viewing the output as what we will set our prior to be for further inference.} for solving the problem (\ref{DirichletProb}). As such we will initially place an appropriate prior on the solution $u$ which encapsulates our prior belief on the solution (such as its smoothness) before utilising detailed knowledge of the specific PDE. We will then consider using an approximation to obtain a posterior distribution which will then become our prior for further inference. We start with utilising the true solution:

\subsubsection{Prior from the true solution}

Formally we have $u=\mathcal{L}^{-1}f$, where $\mathcal{L}^{-1}$ is the solution operator (Green's function) for the problem (\ref{DirichletProb}). Since $f$ is random we see that the solution is also random; in particular it is the push-forward of $f$ by the \textbf{linear} operator $\mathcal{L}^{-1}$. Provided that the linear operator $\mathcal{L}^{-1}$ is bounded it follows from the theory of Gaussian measures (see Proposition 1.18 of \textcolor{blue}{\cite{da2006introduction}}) that $u$ is also Gaussian and in particular has the following distribution:
\begin{equation}
    \label{true_prior}
    u\sim\mathcal{N}(\mathcal{L}^{-1}\bar{f},\mathcal{L}^{-1}K(\mathcal{L}^{-1})^{*})
\end{equation}
This will be one of the two priors we will consider. One should note that this prior indeed utilises the true solution to the PDE. However, for most PDEs it will be intractable to actually compute this prior due to the fact that $\mathcal{L}^{-1}$ is inaccessible. This leads us instead to consider a prior based on a probabilistic numerical method for solving (\ref{DirichletProb}):

\subsubsection{Prior from an approximation}

We will now consider utilising a discretization $\mathcal{F}_{h}$ of the function space $\mathcal{H}$ where $h$ is the mesh size. In particular, we will consider the following information operators:
\begin{equation*}
    I_{j}\boldsymbol{\cdot} = \int_{\Omega}\phi_{j}\boldsymbol{\cdot}\mathrm{d}x, \hspace{0.25cm} j=1,\dots,J
\end{equation*}
where $\phi_{j}\in\mathcal{F}_{h}$ for $j=1,\dots,J$ Note that $J$ is inversely proportional to the mesh size $h$, in particular if $\Omega\subset\mathbb{R}^{2}$ then $J\propto 1/h^2$.
\begin{remark}
    Think of the $\{\phi_{j}\}$ as a basis for finite element spaces.
\end{remark}
Let $\mathcal{I}$ be the concatenation of these information operators, i.e. $\mathcal{I}=(I_1,\dots,I_J)^{T}$. We will refer to $\mathcal{I}$ as the information operator. This information operator essentially involves taking the inner product of a function with against the finite element basis functions. The probabilistic numerical method will involve conditioning on the ``observation" of this information operator. To be more specific consider $\mathcal{I}$ acting on the PDE $\mathcal{L}u=f$. We have,
\begin{equation*}
    \mathcal{I}\mathcal{L}u=\mathcal{I}f=:F
\end{equation*}
where both $\mathcal{I}\mathcal{L}u$ and $F$ are vectors in $\mathbb{R}^{J}$.

\clearpage
